{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import hazelbean as hb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sklearn.metrics\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import gdal\n",
    "import pygeoprocessing\n",
    "# import taskgraph\n",
    "import netCDF4\n",
    "\n",
    "from modeling_utils import *\n",
    "from viz_utils import *\n",
    "from raster_calc_utils import *\n",
    "from spatial_utils import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Regressor Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "df = pd.read_csv('../Data/intermediate/baseline_df_normalized.csv')\n",
    "df = df.set_index('pixel_id')\n",
    "df = df.sample(frac=0.05, replace=False, weights=None, random_state=None, axis=0)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 243 candidates, totalling 486 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed: 36.5min\n",
      "[Parallel(n_jobs=3)]: Done 486 out of 486 | elapsed: 42.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8792526726266376\n",
      "{'colsample_bytree': 1, 'learning_rate': 0.07, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 600, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.75}\n"
     ]
    }
   ],
   "source": [
    "xgb_regressor = xgb.XGBRegressor()\n",
    "\n",
    "parameters1 = {'nthread':[4], \n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, .07, .2], #so called `eta` value\n",
    "              'max_depth': [3, 5, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.5,0.75,1],\n",
    "              'colsample_bytree': [0.5,0.75,1],\n",
    "              'n_estimators': [300,500,600]}\n",
    "\n",
    "parameters2 = {'nthread':[4], \n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.01,.03,.05,.07], #so called `eta` value\n",
    "              'max_depth': [5,6,7,8,9],\n",
    "              'min_child_weight': [3,4,5],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.5,0.75,1],\n",
    "              'colsample_bytree': [0.65,0.75,0.85],\n",
    "              'n_estimators': [300,500,600,700]}\n",
    "\n",
    "parameters3 = {'nthread':[4], \n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.02,.03,.04], #so called `eta` value\n",
    "              'max_depth': [7,8,9,10],\n",
    "              'min_child_weight': [3,4,5],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.65,0.75,0.85],\n",
    "              'colsample_bytree': [0.55,0.65,0.75,0.85],\n",
    "              'n_estimators': [300,500,600,700]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_regressor,\n",
    "                        parameters1,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 3,\n",
    "                        verbose=True)\n",
    "\n",
    "x = df.drop(['log_calories_per_ha'], axis=1)\n",
    "y = df['log_calories_per_ha']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)\n",
    "xgb_grid.fit(X_train,y_train)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2160 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed: 60.4min\n",
      "[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed: 106.0min\n",
      "[Parallel(n_jobs=3)]: Done 1244 tasks      | elapsed: 155.0min\n",
      "[Parallel(n_jobs=3)]: Done 1794 tasks      | elapsed: 226.3min\n"
     ]
    }
   ],
   "source": [
    "xgb_grid = GridSearchCV(xgb_regressor,\n",
    "                        parameters2,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 3,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(X_train,y_train)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = GridSearchCV(xgb_regressor,\n",
    "                        parameters3,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 3,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(X_train,y_train)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spatialenv]",
   "language": "python",
   "name": "conda-env-spatialenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
